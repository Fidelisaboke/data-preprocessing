{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "Refers to the process of transforming raw data into clean data suitable for training, testing, and analysis by an ML model."
   ],
   "id": "5c70058a3afab7c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Installing and importing the required libraries\n",
    "Before doing the data preprocessing tasks, the following libraries are installed:\n",
    "- NumPy: Efficient for working with multidimensional arrays.\n",
    "```\n",
    "pip install numpy\n",
    "```\n",
    "- Pandas: For loading raw data from a file or DBMS, manipulation and analysis of it.\n",
    "```\n",
    "pip install pandas\n",
    "```\n",
    "- Scikit-learn library: For statistical modelling and encoding.\n",
    "```\n",
    "pip install scikit-learn\n",
    "```\n",
    "### Importing the required libraries:"
   ],
   "id": "6cb2a0fdc2088b57"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-06T10:49:15.552569Z",
     "start_time": "2024-10-06T10:49:14.013955Z"
    }
   },
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Loading\n",
    "Load the dataset using the `read` methods provided by the `pandas` library:"
   ],
   "id": "f0c7ee885fcef5a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:47:31.724746Z",
     "start_time": "2024-10-06T11:47:31.711623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "print(df.head())"
   ],
   "id": "b3d1001b7db2b516",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_Age Gender  Dependent_count Education_Level Marital_Status  \\\n",
      "0            45    NaN              3.0     High School        Married   \n",
      "1            49      F              5.0        Graduate         Single   \n",
      "2            51      M              3.0             NaN        Married   \n",
      "3            40      F              4.0     High School        Unknown   \n",
      "4            40      M              NaN      Uneducated        Married   \n",
      "\n",
      "  Income_Category Card_Cateory  \n",
      "0     $60K - $80K         Blue  \n",
      "1  Less than $40K         Blue  \n",
      "2    $80K - $120K         Blue  \n",
      "3  Less than $40K         Blue  \n",
      "4     $60K - $80K         Blue  \n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Summary of the dataset (high-level stats):",
   "id": "685d29e75296ff2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:47:39.978155Z",
     "start_time": "2024-10-06T11:47:39.897828Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.describe())",
   "id": "8840ffa24c241d5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_Age  Dependent_count\n",
      "count     10.000000         9.000000\n",
      "mean      43.700000         2.888889\n",
      "std        6.360468         1.452966\n",
      "min       32.000000         0.000000\n",
      "25%       40.000000         2.000000\n",
      "50%       44.500000         3.000000\n",
      "75%       48.750000         4.000000\n",
      "max       51.000000         5.000000\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating Variable Vectors\n",
    "This the process of separating features (independent variables) from the target (dependent variables). Assuming the target is `Card_Category`:"
   ],
   "id": "9588e4e90967d12c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:47:44.188852Z",
     "start_time": "2024-10-06T11:47:44.167048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Independent variable vector\n",
    "x = df.iloc[:,:-1].values\n",
    "print(x)"
   ],
   "id": "fbd0928e537b205e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45 nan 3.0 'High School' 'Married' '$60K - $80K']\n",
      " [49 'F' 5.0 'Graduate' 'Single' 'Less than $40K']\n",
      " [51 'M' 3.0 nan 'Married' '$80K - $120K']\n",
      " [40 'F' 4.0 'High School' 'Unknown' 'Less than $40K']\n",
      " [40 'M' nan 'Uneducated' 'Married' '$60K - $80K']\n",
      " [44 nan 2.0 'Graduate' 'Married' '$40K - 60K']\n",
      " [51 'M' 4.0 'Unknown' 'Married' '$120K  +']\n",
      " [32 'M' 0.0 'High School' 'Unknown' '$60K - $80K']\n",
      " [37 'M' 3.0 'Uneducated' 'Single' '$60K - $80K']\n",
      " [48 'M' 2.0 'Graduate' 'Single' '$80K - $120K']]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:47:47.331415Z",
     "start_time": "2024-10-06T11:47:47.323479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dependent variable vector\n",
    "y = df.iloc[:, -1].values\n",
    "print(y)"
   ],
   "id": "885b83a40912bd72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blue' 'Blue' 'Blue' 'Blue' 'Blue' 'Blue' 'Gold' 'Silver' 'Blue' 'Blue']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Handling missing values\n",
    "Some values may be missing in the dataset. This is normally indicated by `NaN`. ML models' may perform poorly as a result of these, so they have to be handled"
   ],
   "id": "d92bfd2e5c7f4c69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:47:50.387166Z",
     "start_time": "2024-10-06T11:47:50.377975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cont the number of missing values in each column\n",
    "print(df.isnull().sum())"
   ],
   "id": "ead0fa67d1286c2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_Age       0\n",
      "Gender             2\n",
      "Dependent_count    1\n",
      "Education_Level    1\n",
      "Marital_Status     0\n",
      "Income_Category    0\n",
      "Card_Cateory       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dropping records with missing values",
   "id": "41480294872df2be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:47:53.967407Z",
     "start_time": "2024-10-06T11:47:53.951380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop missing value records and retain the rest (inplace)\n",
    "df.dropna(inplace=True)\n",
    "print(df.to_string())"
   ],
   "id": "fe44e3a2032598be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_Age Gender  Dependent_count Education_Level Marital_Status Income_Category Card_Cateory\n",
      "1            49      F              5.0        Graduate         Single  Less than $40K         Blue\n",
      "3            40      F              4.0     High School        Unknown  Less than $40K         Blue\n",
      "6            51      M              4.0         Unknown        Married        $120K  +         Gold\n",
      "7            32      M              0.0     High School        Unknown     $60K - $80K       Silver\n",
      "8            37      M              3.0      Uneducated         Single     $60K - $80K         Blue\n",
      "9            48      M              2.0        Graduate         Single    $80K - $120K         Blue\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The problem with this is that lots of data could be lost as a result of dropping records with null values.",
   "id": "8500e3ee5c2aef62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Replacing missing values\n",
    "This technique is referred to as **imputing** in simple terms. The missing values are replaced with other values."
   ],
   "id": "eaf1cfb3f25e02e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `SimpleImputer` class from `sklearn.impute` can be used:",
   "id": "5a81d21545ccb4e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:47:59.321661Z",
     "start_time": "2024-10-06T11:47:59.308945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Replacing missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputer object with 'most_frequent' strategy\n",
    "imputer = SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='most_frequent',\n",
    ")\n",
    "\n",
    "# Fit data with imputer\n",
    "imputer.fit(x[:, 1:4])\n",
    "x[:, 1:4] = imputer.transform(x[:, 1:4])\n",
    "print(x)"
   ],
   "id": "a7415a444b953231",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45 'M' 3.0 'High School' 'Married' '$60K - $80K']\n",
      " [49 'F' 5.0 'Graduate' 'Single' 'Less than $40K']\n",
      " [51 'M' 3.0 'Graduate' 'Married' '$80K - $120K']\n",
      " [40 'F' 4.0 'High School' 'Unknown' 'Less than $40K']\n",
      " [40 'M' 3.0 'Uneducated' 'Married' '$60K - $80K']\n",
      " [44 'M' 2.0 'Graduate' 'Married' '$40K - 60K']\n",
      " [51 'M' 4.0 'Unknown' 'Married' '$120K  +']\n",
      " [32 'M' 0.0 'High School' 'Unknown' '$60K - $80K']\n",
      " [37 'M' 3.0 'Uneducated' 'Single' '$60K - $80K']\n",
      " [48 'M' 2.0 'Graduate' 'Single' '$80K - $120K']]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The imputing strategy above uses `most_frequent`. The `strategy='mean'` cannot be used for this case as non-numeric data is present.",
   "id": "11db6766cb1e3672"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Encoding\n",
    "This is the process of converting non-numerical data to numerical values for easy processing of the ML model."
   ],
   "id": "e7f945cfbe457fff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Binary Encoding (One-Hot Encoding)\n",
    "This is the process of converting categorical features to numerical values. It creates a column for every category in a feature, increasing the dimensionality of the dataset."
   ],
   "id": "6fd910be053fa53c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:48:06.901388Z",
     "start_time": "2024-10-06T11:48:06.889418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Column transformer and OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Get categorical column indexes\n",
    "categorical_columns = [1, 3, 4, 5]\n",
    "# ColumnTransformer to OneHotEncode the data\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), categorical_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "x = np.array(ct.fit_transform(x))\n",
    "print(x)"
   ],
   "id": "9147840511433d62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 45 3.0]\n",
      " [1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 49 5.0]\n",
      " [0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 51 3.0]\n",
      " [1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 40 4.0]\n",
      " [0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 40 3.0]\n",
      " [0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 44 2.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 51 4.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 32 0.0]\n",
      " [0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 37 3.0]\n",
      " [0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 48 2.0]]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a7063c6ed540985b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Label Encoding\n",
    "This is replacing text data with a specific numerical value. It's commonly applied to the target."
   ],
   "id": "c712ba88ae7fda0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:52:28.385656Z",
     "start_time": "2024-10-06T11:52:28.351467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "print(y)"
   ],
   "id": "b4eefdc66faca9b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 2 0 0]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Splitting data to Train and Test set\n",
    "This is important so that we can assess the performance of the ML model, tune hyperparameters and prevent data leakage (test data influencing the training process)."
   ],
   "id": "fac14e4356540b33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:24:25.105048Z",
     "start_time": "2024-10-06T13:24:24.878663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split dataset for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assign 25% of the dataset for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)"
   ],
   "id": "897ee9309219a53d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`x_train` values:",
   "id": "a7ee517a4c6488ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:24:48.924690Z",
     "start_time": "2024-10-06T13:24:48.916725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_train\n",
    "print(x_train)"
   ],
   "id": "aaae975ddc9b2a2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 40 3.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 45 3.0]\n",
      " [1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 40 4.0]\n",
      " [1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 49 5.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 32 0.0]\n",
      " [0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 37 3.0]\n",
      " [0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 44 2.0]]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`x_test` values:",
   "id": "7c22b9bf1e51ec45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:25:31.226960Z",
     "start_time": "2024-10-06T13:25:31.194456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_test\n",
    "print(x_test)"
   ],
   "id": "f003e21ced19b4c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 51 3.0]\n",
      " [0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 48 2.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 51 4.0]]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`y_train` values:",
   "id": "1a1dcfc94d2f5195"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:26:49.846817Z",
     "start_time": "2024-10-06T13:26:49.840493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# y_train\n",
    "print(y_train)"
   ],
   "id": "5a9acbbd01135038",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 2 0 0]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`y_test` values:",
   "id": "58be0f721749ef7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:27:38.323994Z",
     "start_time": "2024-10-06T13:27:38.318986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# y_test\n",
    "print(y_test)"
   ],
   "id": "7d7dbb1a0a3b0f1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Scaling\n",
    "A technique that transforms independent variable values to a common scale, ensuring they contribute equally to the ML model.\n",
    "\n",
    "### Why is feature scaling important?\n",
    "1. Larger scale features may have more impact, relative to smaller scale features.\n",
    "2. Larger values may require more computational power, hence the need to transform them so that algorithm performance is improved.\n",
    "3. Feature scaling prevents numerical instabilities, resulting in problems such as overflow and underflow.\n"
   ],
   "id": "3232af4e62efbea9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature Scaling with Standardization",
   "id": "ab49144eecb9d2c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:53:51.290980Z",
     "start_time": "2024-10-06T13:53:51.282351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Apply standard scaling\n",
    "x_train[:,14:] = sc.fit_transform(x_train[:,14:])\n",
    "x_test[:,14:] = sc.transform(x_test[:,14:])"
   ],
   "id": "bf66b23c3b42629",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Outputs after standard scaling:",
   "id": "e4ecfde5773d3e20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:55:08.445729Z",
     "start_time": "2024-10-06T13:55:08.441234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_train\n",
    "print(x_train[:,14:])"
   ],
   "id": "c9e6726770522d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19296124624699 0.09805806756909202]\n",
      " [0.7718449849879598 0.09805806756909202]\n",
      " [-0.19296124624699 0.7844645405527362]\n",
      " [1.5436899699759197 1.4708710135363803]\n",
      " [-1.7366512162229095 -1.9611613513818404]\n",
      " [-0.7718449849879598 0.09805806756909202]\n",
      " [0.5788837387409699 -0.5883484054145522]]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T13:55:25.377842Z",
     "start_time": "2024-10-06T13:55:25.372217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_test\n",
    "print(x_test[:,14:])"
   ],
   "id": "2d800fa3ab668700",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51.0 3.0]\n",
      " [48.0 2.0]\n",
      " [51.0 4.0]]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "194cf39323b23537"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5991f548793ba75c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
